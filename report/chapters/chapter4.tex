% chapter 4
\chapter{Implementation}
In this chapter, We will discuss the implementation
of the two LP formulations from the previous chapter using the chosen tools: Gurobi, or-tools and Optaplanner. We will
also discuss the datasets that are used in the model and background information on hardware that the model is running on.

\section{Hardware and LP Tools Specification}
The tools are run on the same hardware. The hardware is a macbook pro 2014 with is 2.8GHz dual-core Intel i5 processor. It has
8GB 1600 MHz DDR3 memory and is running OSX version 10.9.5. We are using Gurobi version 6.5.O, binary distribution of or-tools version 1.0.0
and Optaplanner version 6.3.0 in this project.

\section{Datasets}
We have five benchmark datasets, two test datasets and one problem dataset for this project.
The benchmark datasets are used to analyse the performance of the tools on typical instances of CVRP. It is based on a study carried out
by Augerat et al \cite{Augerat1998} to determine the best solutions a set of CVRP instances. Test datasets are used to
analyse the performance of the tools on a specific instance of VRP that is similar to the problem, but with much lower load.
Finally, the problem instance is the dataset based on the problem defined in the previous chapter. The test and problem datasets
share the same schema: Node number, Latitude and Longitude. Unlike the other two datasets, the original benchmark datasets came in
XML format and had to be parsed into a matrix format to fit into the LP models. The parsed benchmark dataset has the following schema:
Node number, Latitude, Longitude and Demand. The complete description of the datasets are available in the appendices section.

\section{Model Parameters}
For the CVRP model, we need a few parameters to fit into the model. A model is an LP formulation that is implemented in
in with LP tool in a computer. Like,  Parameters are values like number of vehicles or number of routes for an instance of the model.
Here are some of the parameters that are needed for the CVRP model:
\begin{itemize}
\item Number of vehicles. As per the model defined in this will dictate how many route will be generated.
\item Maximum number of services per route.
\item Number of customers and their respective location
\item Customers' locations
\item Customers' demands. In this model, they are all set to 1.
\end{itemize}

For the CVRPTW model, we will need additional variables on to take into account the time windows. They are as follows:
\begin{itemize}
\item Earliest times for customer to receive service.
\item Latest times for customer to receive service.
\item Service time at each customer. All service time is set to 15 minutes.
\end{itemize}

There are some variables that are generated in the model based on the parameters. They are the complete graph
(The nodes consist of the customers and the depot), Objective value (distance), elapsed time since the start of journey,
routes for each journey for the vehicles.

\section{Model Implementations}
It might be easier to think a model like
a class in object oriented programming.
We have implemented CVRP model using the available datasets with the chosen tools. The CVRPTW are modelled only using
VRP-227 data. The process of building a model is shown in figure 4.1.
\begin{figure}[!ht]
    \tikzstyle{decision} = [diamond, draw, fill=blue!10,
        text width=4.5em, text badly centered, node distance=3cm, inner sep=0pt]
    \tikzstyle{block} = [rectangle, draw, fill=blue!10,
        text width=5em, text centered, rounded corners, minimum height=4em]
    \tikzstyle{line} = [draw, -latex']
    \tikzstyle{cloud} = [draw, ellipse,fill=red!10, node distance=3cm,
        minimum height=2em,inner sep=0pt]
    \begin{center}
        \begin{tikzpicture}[node distance = 2.5cm, auto]
            % Place nodes
            \node [block] (select) {select tool and model};
            \node [block, below of=select] (imp) {implement model};
            \node [cloud, left of=imp] (data) {dataset};
            \node [cloud, right of=imp] (param) {parameters};
            \node [block, below of=imp] (solve) {solve model};
            \node [decision, below of=solve] (decide) {analyse result};
            \node [block, left of=solve, node distance=3cm] (update) {update model};
            \node [block, below of=decide, node distance=3cm] (record) {record solution};
            % Draw edges
            \path [line] (select) -- (imp);
            \path [line] (data) -- (imp);
            \path [line] (param) -- (imp);
            \path [line] (imp) -- (solve);
            \path [line] (solve) -- (decide);
            \path [line] (decide) -| node [near start] {Bad} (update);
            \path [line] (update) -- (solve);
            \path [line] (decide) -- node {Good}(record);
        \end{tikzpicture}
    \end{center}
    \caption{A flowchart of model implementation using LP tools}
\end{figure}

We start off by selecting the model and the model that we want to build. Then we create the model by using
the interface provided by the tool, the data and the appropriate parameters. Once the model is built, we run it
using the chosen tool and analyse the result. If it does not terminate given the time limit or does not give
a satisfactory solution, we update the model and analyse it again. Otherwise, we record the solution.
Checking accuracy of solution is only possible with instances with known solution, which in this case
is only valid for models with VRP-9 as their dataset. We calculate the distance between two nodes using the
distance formula and convert them into metres using the haversine funtion. Haversine function is ..insert explanation
here.. Nodes are represented by integers starting with 1, which is also the depot. We need to test the model if they are
correct, just like in software engineering, where one would test a program by running a unit or regression test.

We have implemented the VRP models with Gurobi using its python interface. Its model implementation consist of two things:
a python script what holds the optimisation model and the data set. It uses the generalised subtour elimination constraints
to remove subtours from the optimal solution, which are added to the constraint store as cut is applied to the graph.
The approach to optimise the model is to start with a complete graph and recursively apply a cut until all the
components are connected. The component in this case is the tours of the vehicles.
Finding the routes for the vehicle is done by identifying the cycles in the list of edges in the optimal tours. It also
uses one additional graph library networkx to conveniently work with graph.

Implementating the mathematical formulation using or-tools is rather similar to Gurobi's. However, the implementation
is easier as or-tools has already build API for solving vehicle routing problems and it uses no additional libraries.
It also comes with routing heuristics such as sweep algorithm, tabu search etc etc, which produce different results as
we shall observe. The optimal routes are build by using the routing API and a 2d array. Each row contains the nodes,
of a particular tour. The downside to this is that we have no full control of the implementation. Although we may
also modify the or-tools solver, but this is not advisable, as per the contributor's instruction, unless the user knows
what he/she is doing.

Optaplanner accepts only XML format input. We define the model in the xml format and let Optaplanner implement the
optimisation procedure. We built the input file that reads data from the dataset and generate the XML input given the
parameters. It comes with a GUI which shows real time optimisation. Like or-tools, modifying the algorithms
for solving LP problems requires a hack at the solver. The results are generated from the GUI and in the form
of an XML file. The exact routes visible from the visualisation, but it is not labelled. The routes can be extracted using
a python script.

We use the chosen tools to run the benchmark datasets. Based on the results and other considerations, we will pick one
tool to solve the given problem.

\section{Review}
Review this chapter... balh dih blah lorem ipsum dolor amet
