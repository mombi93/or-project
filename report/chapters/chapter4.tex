% chapter 4
\chapter{Implementation}
In this chapter, we will discuss the implementation
of the two LP formulations from the previous chapter using the chosen tools.
This project is hosted on a github repository that can be accessed on \url{https://github.com/mombi93/or-project}.

\section{Hardware and LP Tools Specifications}
The tools are run on the same hardware. The hardware is a macbook pro 2014 with is 2.8GHz dual-core Intel i5 processor. It has
8GB 1600 MHz DDR3 memory and is running OSX version 10.9.5. We are using Gurobi version 6.5.0, binary distribution of or-tools version 1.0.0
and Optaplanner version 6.3.0 in this project. We will be using Python version 2.7.5\footnote{https://www.python.org/}
 to implement the models and to parse the datasets throughout this project.

\section{Datasets}
We have three types of datasets: benchmark, test and problem datasets. There are five benchmark datasets, one test dataset and two problem dataset used in this project.

The benchmark dataset is taken from a study carried out
by Augerat \cite{Augerat1998} to determine the outcome of the algorithm that they have developed to solve VRP instances.
The benchmark datasets define a single depot CVRP instance where the customers are randomly dispersed over a \lbrack0,100\rbrack \hspace{0.025cm} by \lbrack0,100\rbrack \hspace{0.025cm} grid.
Each customer has a random demand that is lower than the capacity of the vehicles, all of which are homogeneous and have a capacity of 100.
The datasets have known best solution, which will be used to analyse the performance of our chosen LP tools.

The test dataset T-VRP-9 is used to test if an LP model can solve a VRP instance correctly. It consists of a single depot CVRP
instance with 8 customers that are spread across \lbrack-5,5\rbrack \hspace{0.025cm} by \lbrack-5,5\rbrack \hspace{0.025cm} grid.
This dataset has a known solution that was computed manually. Like the benchmark
datasets, the test datasets comes with pre-defined parameters.

The problem dataset P-VRP-227 is the dataset of the problem defined in chapter 3. The other problem dataset, P-VRP-60, is a subset of the problem dataset
that is used to check the performance of the LP models on the same CVRP instance as the one in the stated problem, but with smaller load.
Unlike the test dataset, the parameters of the problem datasets have to be estimated in order to produce the best optimal solution.

The test and problem datasets
share the same schema: Node number, Latitude and Longitude. Unlike the other two datasets, the original benchmark datasets came in
XML format and had to be parsed into a matrix format to fit into the LP models. The parsed benchmark dataset has the following schema:
Node number, Latitude, Longitude and Demand. Due to the sheer size of the datasets, they will not be included in this report. However,
they are available in the repository.

\section{Model Parameters}
Below are the parameters that are needed for the CVRP model:
\begin{itemize}
\item Number of vehicles - This parameter is specified in the datasets, except on models with estimated parameters.
\item Capacity of vehicle - This parameter is specified in the datasets, except on models with estimated parameters.
\item Number of customers - This parameter is specified in the datasets.
\item Customers' locations - This parameter is specified in the datasets.
\item Customers' demands - This parameter is specified in the benchmark datasets. However, all of customers' demands
for the test and problem datasets are set to one, as defined in the problem definition.
\end{itemize}

For the CVRPTW model, we will need additional parameters on to take into account the time windows. They are as follows:
\begin{itemize}
\item Earliest times for customer to receive service - This parameter is set to 09:00 hours for all customers, as defined in the problem definition.
\item Latest times for customer to receive service - This parameter is set to 17:00 hours for all customers, as defined in the problem definition.
\item Service time at each customer - This parameter is set to 15 minutes, as defined in the problem definition.
\end{itemize}


\section{Model Implementations}
To implement an LP model, we start by selecting the formulation that we want to build. Then we create the model by using
the interface provided by the tool, the data and the appropriate parameters. We ensure that the model follows the objective function
 and the constraints that are defined by the formulation selected. Once the model is built, we run it
using the chosen tool and analyse the result. If the model runs into an error or does not give
a satisfactory solution, we update the model and analyse it again. Otherwise, we record the solution.

To calculate the distance between two nodes using the
distance formula and convert them into metres using the haversine funtion. Haversine function
is a function to computes the great circle distance on a sphere given two pairs of coordinate locations.
The nodes are numbered using integers starting with depot, which is marked with the integer one.

The workflow to build an LP model is shown in figure 4.1.

\vspace{0.5cm}
\begin{figure}[!ht]
    \tikzstyle{decision} = [diamond, draw, fill=blue!10,
        text width=4.5em, text badly centered, node distance=3cm, inner sep=0pt]
    \tikzstyle{block} = [rectangle, draw, fill=blue!10,
        text width=5em, text centered, rounded corners, minimum height=4em]
    \tikzstyle{line} = [draw, -latex']
    \tikzstyle{cloud} = [draw, ellipse,fill=red!10, node distance=3cm,
        minimum height=2em,inner sep=0pt]
    \begin{center}
        \begin{tikzpicture}[node distance = 2.5cm, auto]
            % Place nodes
            \node [block] (select) {select tool and model};
            \node [block, below of=select] (imp) {implement model};
            \node [cloud, left of=imp] (data) {dataset};
            \node [cloud, right of=imp] (param) {parameters};
            \node [block, below of=imp] (solve) {solve model};
            \node [decision, below of=solve] (decide) {analyse result};
            \node [block, left of=solve, node distance=3cm] (update) {update model};
            \node [block, below of=decide, node distance=3cm] (record) {record solution};
            % Draw edges
            \path [line] (select) -- (imp);
            \path [line] (data) -- (imp);
            \path [line] (param) -- (imp);
            \path [line] (imp) -- (solve);
            \path [line] (solve) -- (decide);
            \path [line] (decide) -| node [near start] {Bad} (update);
            \path [line] (update) -- (solve);
            \path [line] (decide) -- node {Good}(record);
        \end{tikzpicture}
    \end{center}
    \caption{A flowchart of model implementation using LP tools}
\end{figure}

We have implemented the VRP models with Gurobi using its python interface and one additional graph library networkx
\footnote{See url:\url{https://networkx.github.io/}}
to conveniently work with graph. It uses the generalised subtour elimination constraints
to remove subtours from the optimal solution, which are added to the constraint store as cut is applied to the graph.
The approach to optimise the model is adopted from an implementation by Pedroso \cite{Pedroso2013}, whereby
a cut is recursively applied onto the graph until no more cut may be added,
in which all the graph components are connected. Within the solver, Gurobi uses branch and bound algorithm
to solve the VRP instance.
Finding the routes for the vehicle is done by identifying the cycles in the edges of the optimal routes.
The implementation of this model is shown in the script cvrp-gurobi.py as shown in the appendix sections.

Implementing the LP formulations using or-tools is rather similar to Gurobi's. However, the implementation uses no
additional library and is easier as or-tools has a built-in routing APIs that implement most of the constraint satisfaction
procedures, such as the SEC and demand constraints. Within the solver, or-tools uses cheapest path heuristic
to solve the VRP instance.
The optimal routes are build by using the routing API and a 2D array. The downside to this is that we have no full control of the implementation. We may
modify the or-tools solver if we want to, but this is not advisable.
The implementation of this model is shown in cvrp-or-tools.py script that is available in the appendix sections.

Optaplanner accepts only XML input format. We define the model in the XML format and Optaplanner will
 implement the optimisation procedure by itself.
We built the python script, shown in xml-gen.py in the appendix section, that reads data from the dataset and generate the XML input given the
parameters.
Unlike the two tools above, it comes with a
 GUI that allows user to interact better with the its API and
 shows real time optimisation. Within the solver, Optaplanner various constructive heuristics \cite{Optaplanner}
to solve the VRP instance. Like or-tools, modifying the algorithms
for solving LP problems requires hacking the solver. The results are generated from the GUI and in the form
of an XML file. The exact routes visible from the visualisation, but it is not labelled. The routes can be extracted using
a python script shown in rt-dist-calc.py that is available in the appendix sections. The generated XML files will not be included in this report due to its sheer size. However, they
are available in the repository.

At this point, we have covered the first three of the seven steps of the methodology used for this project and we are
ready to tackle the core issues of the stated problem. The next step is to test if the implemented models have been modelled
correctly by runninng them with the test dataset T-VRP-9. This dataset defines a small instance of CVRP model, so that we
can quickly check if the model is correct. All of the models must produce a solution that is roughly
similar to the known solution before we run the models on the benchmark datasets. Once all of the models have passed the
testing phase, we run the models with the benchmark datasets and test dataset P-VRP-60 to analyse their performance.
Feature analysis is done while implementing the models. Based on the performance analysis, we select the best model
to solve VRP problem given by the client company.


\section{Review}
In this chapter, we have covered the implementation of the LP models with the various datasets using the chosen tools.
The models that were implemented with Gurobi and or-tools are made using their Python interface. Gurobi optimise the model by using by continuously
 applying cut to the graph until all the graph components are connected.
 LP models created by or-tools were done using the built-in API. To build a model using Optaplanner, which only accepts XML input format, we use a python script to generate XML file that
  defines the problem. Optaplanner will implement the procedure internally.

In the next chapter, we shall show the results and discussions of of the analysis made in this chapter.
